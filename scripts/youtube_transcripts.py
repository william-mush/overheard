#!/usr/bin/env python3
"""
YouTube Transcript Collector for Political Speeches
Uses youtube-transcript-api to extract captions from political videos

Install: pip install youtube-transcript-api google-api-python-client
"""

import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path

try:
    from youtube_transcript_api import YouTubeTranscriptApi
    from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound
except ImportError:
    print("Please install youtube-transcript-api: pip install youtube-transcript-api")
    sys.exit(1)

# Speaker configurations
SPEAKERS = {
    "donald-trump": {
        "name": "Donald Trump",
        "search_terms": ["Trump speech", "Trump rally", "Trump press conference", "Trump interview"],
        "channel_ids": []  # Add official channel IDs if available
    },
    "stephen-miller": {
        "name": "Stephen Miller",
        "search_terms": ["Stephen Miller interview", "Stephen Miller speech", "Stephen Miller press briefing"],
        "channel_ids": []
    },
    "kristi-noem": {
        "name": "Kristi Noem",
        "search_terms": ["Kristi Noem speech", "Kristi Noem interview", "Kristi Noem testimony"],
        "channel_ids": []
    },
    "jd-vance": {
        "name": "JD Vance",
        "search_terms": ["JD Vance speech", "JD Vance interview", "JD Vance senate"],
        "channel_ids": []
    },
    "marjorie-taylor-greene": {
        "name": "Marjorie Taylor Greene",
        "search_terms": ["MTG speech", "Marjorie Taylor Greene congress", "MTG interview"],
        "channel_ids": []
    }
}

# Known video IDs for key speeches (manually curated for quality)
KEY_VIDEOS = [
    # Trump
    {"video_id": "example1", "speaker_id": "donald-trump", "title": "2025 Inaugural Address", "date": "2025-01-20"},
    # Add more curated video IDs here
]


def extract_video_id(url_or_id):
    """Extract video ID from URL or return as-is if already an ID."""
    if "youtube.com" in url_or_id or "youtu.be" in url_or_id:
        # Handle various YouTube URL formats
        patterns = [
            r'(?:v=|/)([0-9A-Za-z_-]{11}).*',
            r'(?:embed/)([0-9A-Za-z_-]{11})',
            r'(?:youtu\.be/)([0-9A-Za-z_-]{11})'
        ]
        for pattern in patterns:
            match = re.search(pattern, url_or_id)
            if match:
                return match.group(1)
    return url_or_id


def get_transcript(video_id):
    """Fetch transcript for a YouTube video."""
    try:
        # Try to get manual captions first, then auto-generated
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)

        # Prefer manually created English transcripts
        try:
            transcript = transcript_list.find_manually_created_transcript(['en'])
        except:
            # Fall back to auto-generated
            try:
                transcript = transcript_list.find_generated_transcript(['en'])
            except:
                return None

        # Fetch the actual transcript
        transcript_data = transcript.fetch()

        # Combine into full text
        full_text = " ".join([entry['text'] for entry in transcript_data])

        # Clean up the text
        full_text = re.sub(r'\[.*?\]', '', full_text)  # Remove [Music], [Applause], etc.
        full_text = re.sub(r'\s+', ' ', full_text).strip()

        return {
            "full_text": full_text,
            "segments": transcript_data,
            "language": transcript.language,
            "is_generated": transcript.is_generated
        }

    except TranscriptsDisabled:
        print(f"  Transcripts disabled for video {video_id}")
        return None
    except NoTranscriptFound:
        print(f"  No transcript found for video {video_id}")
        return None
    except Exception as e:
        print(f"  Error fetching transcript for {video_id}: {e}")
        return None


def process_video(video_id, speaker_id, title, date, source_url=None):
    """Process a single video and return transcript data."""
    print(f"Processing: {title} ({video_id})")

    transcript = get_transcript(video_id)
    if not transcript:
        return None

    speaker = SPEAKERS.get(speaker_id, {"name": speaker_id})

    return {
        "id": f"yt-{video_id}",
        "speaker": speaker["name"],
        "speakerId": speaker_id,
        "date": date,
        "source": "YouTube",
        "sourceUrl": source_url or f"https://www.youtube.com/watch?v={video_id}",
        "eventType": "speech",
        "title": title,
        "fullText": transcript["full_text"],
        "isAutoGenerated": transcript["is_generated"],
        "extractedQuotes": []  # Will be filled by analysis pipeline
    }


def collect_from_video_list(video_list, output_file):
    """Collect transcripts from a list of video configurations."""
    transcripts = []

    for video in video_list:
        video_id = extract_video_id(video.get("video_id", video.get("url", "")))
        if not video_id:
            continue

        result = process_video(
            video_id=video_id,
            speaker_id=video.get("speaker_id"),
            title=video.get("title", "Unknown"),
            date=video.get("date", datetime.now().strftime("%Y-%m-%d")),
            source_url=video.get("source_url")
        )

        if result:
            transcripts.append(result)

    # Save results
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w') as f:
        json.dump({
            "source": "YouTube Transcripts",
            "collected_at": datetime.now().isoformat(),
            "count": len(transcripts),
            "transcripts": transcripts
        }, f, indent=2)

    print(f"\nCollected {len(transcripts)} transcripts to {output_file}")
    return transcripts


def collect_single_video(url_or_id, speaker_id, title=None, date=None):
    """Collect transcript from a single video URL or ID."""
    video_id = extract_video_id(url_or_id)

    result = process_video(
        video_id=video_id,
        speaker_id=speaker_id,
        title=title or f"Video {video_id}",
        date=date or datetime.now().strftime("%Y-%m-%d")
    )

    if result:
        print(f"\nTranscript collected: {len(result['fullText'])} characters")
        print(f"Auto-generated: {result['isAutoGenerated']}")
        return result

    return None


def main():
    """Main entry point."""
    import argparse

    parser = argparse.ArgumentParser(description="Collect YouTube transcripts for political speeches")
    parser.add_argument("--video", "-v", help="Single video URL or ID to process")
    parser.add_argument("--speaker", "-s", help="Speaker ID (e.g., 'donald-trump')")
    parser.add_argument("--title", "-t", help="Video title")
    parser.add_argument("--date", "-d", help="Video date (YYYY-MM-DD)")
    parser.add_argument("--output", "-o", default="../data/youtube_transcripts.json", help="Output file")
    parser.add_argument("--batch", "-b", help="JSON file with list of videos to process")

    args = parser.parse_args()

    if args.video:
        # Process single video
        if not args.speaker:
            print("Error: --speaker is required when processing a single video")
            sys.exit(1)

        result = collect_single_video(args.video, args.speaker, args.title, args.date)
        if result:
            # Append to existing transcripts or create new
            output_path = Path(args.output)
            existing = {"transcripts": []}
            if output_path.exists():
                with open(output_path) as f:
                    existing = json.load(f)

            existing["transcripts"].append(result)
            existing["collected_at"] = datetime.now().isoformat()
            existing["count"] = len(existing["transcripts"])

            with open(output_path, 'w') as f:
                json.dump(existing, f, indent=2)

            print(f"Saved to {args.output}")

    elif args.batch:
        # Process batch from JSON file
        with open(args.batch) as f:
            video_list = json.load(f)
        collect_from_video_list(video_list, args.output)

    else:
        # Process curated key videos
        print("Processing curated key videos...")
        collect_from_video_list(KEY_VIDEOS, args.output)


if __name__ == "__main__":
    main()
